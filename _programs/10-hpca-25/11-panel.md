---
edition: hpca-25
type: panel
time_start: 2025-03-02 15:30:00
time_end: 2025-03-02 16:30:00
title: "The evolution of scaling laws and what it means for sustainable AI computing"
moderator:
    name: Satyam Srivastava
    affiliation: d-Matrix
panelists:
- name: Onur Mutlu
  affiliation: ETH Zurich
- name: Huichu Liu
  affiliation: Meta
- name: Yingyan (Celine) Yin
  affiliation: Georgia Tech
- name: Song Han
  affiliation: MIT
---

We are witnessing a paradigm shift in the development of AI technology. For last several years, creation of the next frontier language models has largely followed the recipe of AI scaling law â€“ larger model + more data + more compute leads to better capability. Lately though, this recipe has become unsustainable, even for the largest organizations. This has spurred clever innovations across data conditioning, reinforcement learning, knowledge distillation, inference-time computing, and many more. Not only have these innovations helped overcome the wall of traditional scaling, it has lowered the barrier to accessing top tier AI technology and also shifted some computational demand from training to inference. This panel will explore the implications and possibilities of this new landscape of AI computing and how to make it more sustainable.
