{% assign accepting_editions = site.editions|where: "is_accepting_submission",true|sort:"event_date" %}

<div class="row">
  <div class="col s12">
      <h3 class="header"><i class="material-icons">description</i> Workshop Objective</h3>
	<p>In the Eleventh edition of EMC2 workshop, we plan to facilitate conversation about the sustainability of large-scale AI computingsystems being developed to meet the ever-increasing demands of generative AI. This involves discussions spanning multiple interre-lated areas. First, we continue to serve as the leading forums for discussing the energy-efficiency aspect of GenAI workloads whichdirectly impact the overall viability and economic value of AI technology. Second, we reassess the scaling laws of AI with theprevalence of agentic, multi-modal, and reasoning-based models in conjunction with novel techniques such as a highly sparse expertarchitecture and disaggregated computation. Finally, we discuss sustainable and high-performance computing paradigms towardsefficient datacenters and hybrid computing models that can cater to the exponential growth in model sizes, application areas, anduser base. This would allow us to explore ideas to build the hardware, software, systems, and scaling infrastructure, as well as modelarchitectures that make AI technology even more prevalent and accessible.
	</p>
  </div>
</div>
<div class="row">
  {% assign _col_size="s12 m6" %}
  {% if include.hide_cfp %}
    {% assign _col_size="s12" %}
  {% else %}
  <div class="col {{ _col_size }}">
    <h3 class="header"><i class="material-icons">chat</i> Call for Papers</h3>
    <p>
    The goal of this Workshop is to provide a forum for researchers and industry experts who are exploring novel ideas, tools and techniques to
improve the energy efficiency of MLLMs as it is practised today and would evolve in the next decade. We envision that only through close
collaboration between industry and the academia we will be able to address the difficult challenges and opportunities of reducing the carbon
footprint of AI and its uses. We have tailored our program to best serve the participants in a fully digital setting. Our forum facilitates active
exchange of ideas through:
</p>

    <ul class="browser-default list">

	    <li>Keynotes, invited talks and discussion panels by leading researchers from industry and academia</li>
	    <li>Peer-reviewed papers on latest solutions including works-in-progress to seek directed feedback from experts</li>
	    <li>Independent publication of proceedings through IEEE CPS</li>

    </ul>
    <p>
We invite full-length papers describing original, cutting-edge, and even work-in-progress research projects about efficient machine learning. Suggested topics for papers include, but are not limited to the ones listed below:    </p>

  </div>
  {% endif %}
  <div class="col {{ _col_size }}">
    <h3 class="header"><i class="material-icons">format_list_bulleted</i> Topics for the Workshop</h3>
    <ul class="browser-default list">
		<li>Neural network architectures for resource constrained applications.</li>
		<li>Efficient hardware designs to implement neural networks including sparsity, locality, and systolic designs.</li>
		<li>Power and performance efficient memory architectures suited for neural networks.</li>
		<li>Network reduction techniques â€“ approximation, quantization, reduced precision, pruning, distillation, and reconfiguration.</li>
		<li>Exploring interplay of precision, performance, power, and energy through benchmarks, workloads, and characterization.</li>
		<li>Performance potential, limit studies, bottleneck analysis, profiling, and synthesis of workloads.</li>
		<li>Explorations and architctures aimed to promote sustainable computing.</li>
		<li>Simulation and emulation techniques, frameworks, tools, and platforms for machine learning.</li>
		<li>Optimizations to improve performance of training techniques including on-device and large-scale learning.</li>
		<li>Load balancing and efficient task distribution, communication and computation overlapping for optimal performance.</li>
		<li>Verification, validation, determinism, robustness, bias, safety, and privacy challenges in AI systems.</li>
		<li>Efficient deployment strategies for edge and distributed environments.</li>
		<li>Model compression and optimization techniques that preserve reasoning and problem-solving capabilities.</li>
		<li>Architectures and frameworks for multi-agent systems and retrieval-augmented generation (RAG) pipelines.</li>
		<li>Systems-level approaches for scaling future foundation models (e.g., Llama 4, GPT-5 and beyond).</li>
		<h3 class="header">We will follow that same formatting guidelines and duplicate submission policies as HPCA.</h3>
    </ul>
  </div>
       <div class="center-align">
            {% for ed in accepting_editions %}
            <a class="waves-effect waves-light btn-large center-align"
                href="/submission" target="_blank">
                Submit to EMC<sup>2</sup> ({{ ed.colocated_short}}) <i class="material-icons right">send</i>
            </a>

            {% if ed.has_emcc_submission %}
            <a class="waves-effect waves-light btn-large center-align"
                href="/emcc" target="_blank">
                Submit to EMC<sup>2</sup> ({{ ed.colocated_short}}) Model Compression Challenge
                <i class="material-icons right">cloud_upload</i>
            </a>
            {% endif %}
            {% endfor %}
        </div>
</div>
